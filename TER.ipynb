{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX75d6mo9p-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054a561e-4770-4f17-864a-bf8e0a3f371e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/NLP/@SMT/results/USMT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVTkNYUIfMO4",
        "outputId": "5043d6d3-f022-45d5-8833-f34d89f8bd30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/17P1p7VqCPwRkyqNN5NdG-2IU5CLO5HuP/NLP/@SMT/results/USMT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdkBZ5HYuWtd",
        "outputId": "b200eeb4-89fe-4c87-9e61-ff4762e9825f"
      },
      "source": [
        "#-------- Installation\n",
        "!git clone https://github.com/BramVanroy/pyter.git\n",
        "%cd pyter\n",
        "!pip install -e ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pyter'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Total 212 (delta 0), reused 0 (delta 0), pack-reused 212\u001b[K\n",
            "Receiving objects: 100% (212/212), 38.75 KiB | 575.00 KiB/s, done.\n",
            "Resolving deltas: 100% (101/101), done.\n",
            "/content/pyter\n",
            "Obtaining file:///content/pyter\n",
            "Installing collected packages: pyter3\n",
            "  Running setup.py develop for pyter3\n",
            "Successfully installed pyter3-0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_lnxznK9u5d"
      },
      "source": [
        "import pyter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAWahFAD9vs8"
      },
      "source": [
        "ref = u'SAUDI ARABIA denied THIS WEEK information published in the AMERICAN new york times'.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sHouD6A9zHl"
      },
      "source": [
        "hyp = u'THIS WEEK THE SAUDIS denied information published in the new york times'.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4mWl_Fu95fM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ddc8839-0d50-436a-97ec-3d916ee08650"
      },
      "source": [
        "'%.3f' % pyter.ter(hyp, ref)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.308'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waWD1Az7i_6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da6aa76-aed6-460b-9bb5-6fcf4ca204a5"
      },
      "source": [
        "from nltk import word_tokenize \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "translated_file = \"/content/drive/MyDrive/DataAugment/eda/en-ta/ta_base-sr-ri-rs-rd.trasnlated.ta\"\n",
        "reference_file = \"/content/drive/MyDrive/DataAugment/eda/en-ta/test_ta_en.ta\"\n",
        "f5 = open('/content/ter_score_ur1.txt', \"a+\")\n",
        "with open(translated_file, \"r\") as f1, open(reference_file, \"r\") as f2:\n",
        "  lines1 = [line.rstrip('\\n') for line in f1]\n",
        "  print(len(lines1))\n",
        "  lines2 = [line.rstrip('\\n') for line in f2]\n",
        "  print(len(lines2))\n",
        "  for l1,l2 in zip(lines1,lines2):\n",
        "    tokens_ref=[word_tokenize(l2)]\n",
        "    #print(tokens_ref)\n",
        "    tokens_translate=word_tokenize(l1)\n",
        "    #print(tokens_translate)\n",
        "    score ='%.3f' % pyter.ter(tokens_translate, tokens_ref)\n",
        "    f5.write(str(score)+'\\n')\n",
        "f5.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "1000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdfA3fu00OVq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}